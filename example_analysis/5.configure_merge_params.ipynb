{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure Merge Module Params\n",
    "\n",
    "This notebook should be used as a test for ensuring correct merge parameters before merge processing.\n",
    "Cells marked with `SET PARAMETERS` contain crucial variables that need to be set according to your specific experimental setup and data organization.\n",
    "Please review and modify these variables as needed before proceeding with the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SET PARAMETERS\n",
    "\n",
    "### Fixed parameters for merge processing\n",
    "\n",
    "- `CONFIG_FILE_PATH`: Path to a Brieflow config file used during processing. Absolute or relative to where workflows are run from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_FILE_PATH = \"config/config.yml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import yaml\n",
    "import pandas as pd\n",
    "\n",
    "from lib.shared.file_utils import get_filename\n",
    "from lib.shared.configuration_utils import (\n",
    "    plot_combined_tile_grid,\n",
    "    plot_merge_example,\n",
    "    CONFIG_FILE_HEADER,\n",
    ")\n",
    "from lib.merge.hash import hash_cell_locations, initial_alignment\n",
    "from lib.merge.eval_alignment import plot_alignment_quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SET PARAMETERS\n",
    "\n",
    "### Parameters for testing merge processing\n",
    "- `TEST_WELL`: Well identifier used for testing configuration \n",
    "\n",
    "### Parameters for metadata extraction\n",
    "- `SBS_METADATA_CYCLE`: Cycle number for extracting SBS data positions\n",
    "- `SBS_METADATA_CHANNEL`: Optional channel for SBS metadata. This is necessary in the case that multiple channel-based images were acquired, and therefore, multiple channel-based metadata files exist.\n",
    "- `PH_METADATA_CHANNEL`: Optional channel for phenotype metadata. This is necessary in the case that multiple channel-based images were acquired, and therefore, multiple channel-based metadata files exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Figure out good way to use testing data for example analysis...\n",
    "# for now just use copied files from denali screen\n",
    "\n",
    "TEST_WELL = \"A1\"\n",
    "\n",
    "SBS_METADATA_CYCLE = 1\n",
    "SBS_METADATA_CHANNEL = None\n",
    "PH_METADATA_CHANNEL = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config file and determine root path\n",
    "with open(CONFIG_FILE_PATH, \"r\") as config_file:\n",
    "    config = yaml.safe_load(config_file)\n",
    "ROOT_FP = Path(config[\"all\"][\"root_fp\"])\n",
    "\n",
    "# load phenotype and SBS metadata dfs\n",
    "ph_filename_params = {}\n",
    "if PH_METADATA_CHANNEL is not None:\n",
    "    ph_filename_params[\"channel\"] = PH_METADATA_CHANNEL\n",
    "\n",
    "ph_test_metadata_fp = (\n",
    "    ROOT_FP\n",
    "    / \"preprocess\"\n",
    "    / \"metadata\"\n",
    "    / \"phenotype\"\n",
    "    / get_filename(ph_filename_params, \"combined_metadata\", \"hdf5\")\n",
    ")\n",
    "ph_test_metadata = pd.read_hdf(ph_test_metadata_fp)\n",
    "ph_test_metadata = ph_test_metadata[ph_test_metadata[\"well\"] == TEST_WELL]\n",
    "\n",
    "sbs_filename_params = {\"cycle\": SBS_METADATA_CYCLE}\n",
    "if SBS_METADATA_CHANNEL is not None:\n",
    "    sbs_filename_params[\"channel\"] = SBS_METADATA_CHANNEL\n",
    "\n",
    "sbs_test_metadata_fp = (\n",
    "    ROOT_FP\n",
    "    / \"preprocess\"\n",
    "    / \"metadata\"\n",
    "    / \"sbs\"\n",
    "    / get_filename(sbs_filename_params, \"combined_metadata\", \"hdf5\")\n",
    ")\n",
    "sbs_test_metadata = pd.read_hdf(sbs_test_metadata_fp)\n",
    "sbs_test_metadata = sbs_test_metadata[sbs_test_metadata[\"well\"] == TEST_WELL]\n",
    "\n",
    "# create plot with combined tile view\n",
    "combined_tile_grid = plot_combined_tile_grid(ph_test_metadata, sbs_test_metadata)\n",
    "combined_tile_grid.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SET PARAMETERS\n",
    "\n",
    "### Parameters for testing merge processing\n",
    "\n",
    "- `INITIAL_SITES`: Combinations of phenotype and SBS tiles used for configuring merge module parameters. Based on the combined grid above, set 6 aligned intial sites. We will load images for one of those sites, to ensure that we can visualize cell patterns (using the DAPI channel) that correspond between two tiles that will make up our initial sites. We recommend using aligned sites from across the plate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "INITIAL_SITES = [[5, 0], [141, 32], [370, 86], [896, 212], [1163, 270], [1599, 376]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derive sites for phenotype and sbs\n",
    "phenotype_tiles = [site[0] for site in INITIAL_SITES]\n",
    "sbs_tiles = [site[1] for site in INITIAL_SITES]\n",
    "\n",
    "# Derive phenotype alignment hash\n",
    "phenotype_info_fp = (\n",
    "    ROOT_FP / \"phenotype\" / \"hdfs\" / get_filename({}, \"phenotype_info\", \"hdf5\")\n",
    ")\n",
    "phenotype_info = pd.read_hdf(phenotype_info_fp)\n",
    "phenotype_info = phenotype_info[phenotype_info[\"well\"] == TEST_WELL]\n",
    "phenotype_info_hash = hash_cell_locations(phenotype_info)\n",
    "\n",
    "# Derive SBS alignment hash\n",
    "sbs_info_fp = ROOT_FP / \"sbs\" / \"hdfs\" / get_filename({}, \"sbs_info\", \"hdf5\")\n",
    "sbs_info = pd.read_hdf(sbs_info_fp)\n",
    "sbs_info = sbs_info[sbs_info[\"well\"] == TEST_WELL]\n",
    "sbs_info_hash = hash_cell_locations(sbs_info).rename(columns={\"tile\": \"site\"})\n",
    "\n",
    "# Perform alignment for initial sites\n",
    "initial_alignment_df = initial_alignment(\n",
    "    phenotype_info_hash, sbs_info_hash, initial_sites=INITIAL_SITES\n",
    ")\n",
    "initial_alignment_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SET PARAMETERS\n",
    "\n",
    "### Visualize gating strategy based on initial alignment\n",
    "\n",
    "- `DET_RANGE`: Enforces valid magnification ratios between phenotype and genotype images. It needs to be adjusted based on:\n",
    "    - Objective magnifications used (e.g., 20X vs 10X)\n",
    "    - Camera binning settings (e.g., 2x2 binning vs unbinned)\n",
    "    - To calculate for your setup:\n",
    "        1. Determine total magnification difference (objectives × binning)\n",
    "        2. Use (min/difference², max/difference²) where min/max are typically 0.9-1.15\n",
    "    - You can narrow or expand the suggested `DET_RANGE` based on how closely or widely you want to ensure matches\n",
    "- `SCORE` This parameter is the score of the transformation, typically 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DET_RANGE = [0.06, 0.065]\n",
    "SCORE = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_alignment_quality(\n",
    "    initial_alignment_df, det_range=DET_RANGE, score=SCORE, xlim=(0, 0.1), ylim=(0, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SET PARAMETERS\n",
    "\n",
    "### Visualize cell matches based on initial alignment\n",
    "\n",
    "- `THRESHOLD`: Determines the maximum euclidean distance between a phenotype point and its matched SBS point for them to be considered a valid match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alignment_vec_example = initial_alignment_df[\n",
    "    (initial_alignment_df[\"tile\"] == INITIAL_SITES[0][0])\n",
    "    & (initial_alignment_df[\"site\"] == INITIAL_SITES[0][1])\n",
    "].iloc[0]\n",
    "\n",
    "plot_merge_example(\n",
    "    phenotype_info,\n",
    "    sbs_info,\n",
    "    alignment_vec_example,\n",
    "    threshold=THRESHOLD,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add merge parameters to config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add merge section\n",
    "config[\"merge_process\"] = {\n",
    "    \"sbs_metadata_cycle\": SBS_METADATA_CYCLE,\n",
    "    \"sbs_metadata_channel\": SBS_METADATA_CHANNEL,\n",
    "    \"ph_metadata_channel\": PH_METADATA_CHANNEL,\n",
    "    \"initial_sites\": INITIAL_SITES,\n",
    "    \"det_range\": DET_RANGE,\n",
    "    \"score\": SCORE,\n",
    "    \"threshold\": THRESHOLD,\n",
    "}\n",
    "\n",
    "# Write the updated configuration back with markdown-style comments\n",
    "with open(CONFIG_FILE_PATH, \"w\") as config_file:\n",
    "    # Write the introductory markdown-stylåe comments\n",
    "    config_file.write(CONFIG_FILE_HEADER)\n",
    "\n",
    "    # Dump the updated YAML structure, keeping markdown comments for sections\n",
    "    yaml.dump(config, config_file, default_flow_style=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brieflow_configuration",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
