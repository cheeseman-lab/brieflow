{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OME-Zarr Metadata Enrichment — Starter Notebook\n",
    "\n",
    "This notebook walks through the OME-Zarr outputs from the brieflow pipeline test data.\n",
    "It demonstrates how to inspect, enrich, and validate zarr store metadata so the undergrad\n",
    "can implement each enrichment step for real.\n",
    "\n",
    "**Prerequisites:** Run `bash run_brieflow_omezarr.sh` from the `small_test_analysis/` directory first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zarr\n",
    "\n",
    "# Add brieflow workflow to path so we can import its libraries\n",
    "sys.path.insert(0, str(Path(\"../../../workflow\").resolve()))\n",
    "from lib.shared.io import read_image, save_image\n",
    "\n",
    "# Root paths\n",
    "ZARR_ROOT = Path(\"../brieflow_output_zarr\")\n",
    "assert ZARR_ROOT.exists(), f\"Run the zarr pipeline first: {ZARR_ROOT}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Explore the output directory structure\n",
    "\n",
    "The pipeline produces three module outputs, each with `images/`, `hcs/`, and tabular data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for module in [\"preprocess\", \"sbs\", \"phenotype\"]:\n",
    "    module_dir = ZARR_ROOT / module\n",
    "    if not module_dir.exists():\n",
    "        continue\n",
    "    subdirs = sorted(d.name for d in module_dir.iterdir() if d.is_dir())\n",
    "    print(f\"{module}/  →  {subdirs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Read pipeline metadata (parquet)\n",
    "\n",
    "The preprocess module extracts hardware metadata from the raw images.\n",
    "This is where pixel sizes, channel info, and other acquisition parameters live."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read phenotype metadata\n",
    "ph_meta = pd.read_parquet(\n",
    "    ZARR_ROOT / \"preprocess/metadata/phenotype/1/A1/combined_metadata.parquet\"\n",
    ")\n",
    "print(f\"Shape: {ph_meta.shape}\")\n",
    "print(f\"Columns: {list(ph_meta.columns)}\")\n",
    "ph_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key fields for metadata enrichment\n",
    "print(\"Pixel sizes (from hardware):\")\n",
    "print(f\"  X: {ph_meta['pixel_size_x'].iloc[0]} µm\")\n",
    "print(f\"  Y: {ph_meta['pixel_size_y'].iloc[0]} µm\")\n",
    "print(f\"  Z: {ph_meta['pixel_size_z'].iloc[0]} µm\")\n",
    "print(f\"Objective: {ph_meta['objective_magnification'].iloc[0]}x\")\n",
    "print(f\"Channels: {ph_meta['channels'].iloc[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Inspect a per-tile zarr store\n",
    "\n",
    "Each tile is written as an independent OME-Zarr store with pyramid levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a phenotype tile\n",
    "tile_store = ZARR_ROOT / \"preprocess/images/phenotype/1/A1/2/image.zarr\"\n",
    "\n",
    "# Read zarr.json (OME-NGFF v0.5 uses zarr v3 format)\n",
    "with open(tile_store / \"zarr.json\") as f:\n",
    "    tile_meta = json.load(f)\n",
    "\n",
    "print(\"=== zarr.json ===\")\n",
    "print(json.dumps(tile_meta, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the OME multiscale metadata\n",
    "ome = tile_meta[\"attributes\"][\"ome\"]\n",
    "ms = ome[\"multiscales\"][0]\n",
    "\n",
    "print(\"Axes:\")\n",
    "for ax in ms[\"axes\"]:\n",
    "    print(f\"  {ax['name']} ({ax['type']})  ←  MISSING: 'unit' key\")\n",
    "\n",
    "print(\"\\nPyramid levels:\")\n",
    "for ds in ms[\"datasets\"]:\n",
    "    scales = ds[\"coordinateTransformations\"][0][\"scale\"]\n",
    "    print(f\"  level {ds['path']}: scale={scales}  ←  MISSING: real pixel sizes\")\n",
    "\n",
    "print(\"\\nOmero channels:\")\n",
    "omero = tile_meta[\"attributes\"].get(\"omero\", {})\n",
    "for ch in omero.get(\"channels\", []):\n",
    "    print(f\"  {ch['label']}  ←  MISSING: real name, contrast window\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read image data at different pyramid levels\n",
    "root = zarr.open_group(str(tile_store), mode=\"r\")\n",
    "for level in [\"0\", \"1\", \"2\", \"3\", \"4\"]:\n",
    "    if level in root:\n",
    "        arr = root[level]\n",
    "        print(\n",
    "            f\"Level {level}: shape={arr.shape}, dtype={arr.dtype}, chunks={arr.chunks}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare: using the high-level read_image() API\n",
    "img = read_image(tile_store)\n",
    "print(f\"read_image() shape: {img.shape}, dtype: {img.dtype}\")\n",
    "print(\n",
    "    f\"  (singleton channel dim was squeezed: original zarr shape was {root['0'].shape})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Inspect a label store\n",
    "\n",
    "Segmentation outputs (nuclei, cells) are zarr stores with an `image-label` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_store = ZARR_ROOT / \"sbs/images/1/A1/0/nuclei.zarr\"\n",
    "with open(label_store / \"zarr.json\") as f:\n",
    "    label_meta = json.load(f)\n",
    "\n",
    "is_label = \"image-label\" in label_meta.get(\"attributes\", {})\n",
    "print(f\"Is label store: {is_label}\")\n",
    "print(f\"Label dtype: {zarr.open_group(str(label_store), mode='r')['0'].dtype}\")\n",
    "print(f\"  ← Should be int32 for segmentation masks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5. Inspect the HCS plate stores\n\nThe HCS assembly step creates spec-compliant plate zarrs using symlinks to per-tile data.\nEach module that produces zarr images gets its own HCS output:\n- **preprocess** — per-modality: `hcs/sbs/1.zarr`, `hcs/phenotype/1.zarr`\n- **sbs** — `hcs/1.zarr` (aligned + intermediates + labels)\n- **phenotype** — `hcs/1.zarr` (aligned + intermediates + labels)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Compare HCS layout across all three modules\nhcs_roots = {\n    \"sbs\": ZARR_ROOT / \"sbs/hcs\",\n    \"phenotype\": ZARR_ROOT / \"phenotype/hcs\",\n    \"preprocess\": ZARR_ROOT / \"preprocess/hcs\",\n}\n\nfor module, hcs_dir in hcs_roots.items():\n    if not hcs_dir.exists():\n        print(f\"{module}: no HCS output\")\n        continue\n    plate_zarrs = sorted(hcs_dir.rglob(\"*.zarr\"))\n    paths = [str(p.relative_to(hcs_dir)) for p in plate_zarrs]\n    print(f\"{module}:  {paths}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Inspect plate + well metadata for SBS and phenotype\nfor module, plate_path in [\n    (\"sbs\", ZARR_ROOT / \"sbs/hcs/1.zarr\"),\n    (\"phenotype\", ZARR_ROOT / \"phenotype/hcs/1.zarr\"),\n]:\n    with open(plate_path / \"zarr.json\") as f:\n        pmeta = json.load(f)\n    plate = pmeta[\"attributes\"][\"ome\"][\"plate\"]\n    wells = [w[\"path\"] for w in plate[\"wells\"]]\n    print(f\"--- {module} plate 1 ---\")\n    print(f\"  Rows: {[r['name'] for r in plate['rows']]}\")\n    print(f\"  Columns: {[c['name'] for c in plate['columns']]}\")\n    print(f\"  Wells: {wells}\")\n\n    # Show fields in first well\n    well_dir = plate_path / wells[0].replace(\"/\", \"/\")\n    with open(well_dir / \"zarr.json\") as f:\n        wmeta = json.load(f)\n    fields = [img[\"path\"] for img in wmeta[\"attributes\"][\"ome\"][\"well\"][\"images\"]]\n    print(f\"  Fields in {wells[0]}: {fields}\")\n    print()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Field contents side-by-side: SBS vs phenotype\n# SBS has more intermediate image types (per-cycle); phenotype is simpler\nfor module, field_path in [\n    (\"sbs\", ZARR_ROOT / \"sbs/hcs/1.zarr/A/1/0\"),\n    (\"phenotype\", ZARR_ROOT / \"phenotype/hcs/1.zarr/A/1/2\"),\n]:\n    print(f\"--- {module} field ---\")\n    for item in sorted(field_path.iterdir()):\n        kind = \"symlink\" if item.is_symlink() else \"dir\" if item.is_dir() else \"file\"\n        print(f\"  {item.name:30s}  ({kind})\")\n    print()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Labels: verify they match the direct per-tile stores (both modules)\nfor module, field_labels, direct_nuclei in [\n    (\n        \"sbs\",\n        ZARR_ROOT / \"sbs/hcs/1.zarr/A/1/0/labels\",\n        ZARR_ROOT / \"sbs/images/1/A1/0/nuclei.zarr\",\n    ),\n    (\n        \"phenotype\",\n        ZARR_ROOT / \"phenotype/hcs/1.zarr/A/1/2/labels\",\n        ZARR_ROOT / \"phenotype/images/1/A1/2/nuclei.zarr\",\n    ),\n]:\n    print(f\"--- {module} labels ---\")\n    with open(field_labels / \"zarr.json\") as f:\n        lmeta = json.load(f)\n    label_names = lmeta[\"attributes\"][\"ome\"][\"labels\"]\n    print(f\"  Available: {label_names}\")\n\n    # Verify HCS path gives same data as direct path\n    nuc_hcs = read_image(field_labels / \"nuclei\")\n    nuc_direct = read_image(direct_nuclei)\n    print(f\"  HCS shape: {nuc_hcs.shape}, direct shape: {nuc_direct.shape}\")\n    print(f\"  Identical: {np.array_equal(nuc_hcs, nuc_direct)}\")\n    print()"
  },
  {
   "cell_type": "code",
   "source": "# Preprocess has per-modality HCS subdirs (sbs/, phenotype/) — unique layout\npreprocess_hcs = ZARR_ROOT / \"preprocess/hcs\"\nprint(\"Preprocess HCS layout (per-modality):\")\nfor modality_dir in sorted(preprocess_hcs.iterdir()):\n    if not modality_dir.is_dir():\n        continue\n    plate_zarrs = sorted(modality_dir.glob(\"*.zarr\"))\n    for pz in plate_zarrs:\n        with open(pz / \"zarr.json\") as f:\n            pmeta = json.load(f)\n        wells = [w[\"path\"] for w in pmeta[\"attributes\"][\"ome\"][\"plate\"][\"wells\"]]\n        print(f\"  {modality_dir.name}/{pz.name}: wells={wells}\")\n\n# Show field contents — preprocess SBS has per-cycle image subgroups\nfield = preprocess_hcs / \"sbs/1.zarr/A/1/2\"\nprint(f\"\\nPreprocess SBS field contents:\")\nfor item in sorted(field.iterdir()):\n    kind = \"symlink\" if item.is_symlink() else \"dir\" if item.is_dir() else \"file\"\n    print(f\"  {item.name:30s}  ({kind})\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Metadata enrichment tasks\n",
    "\n",
    "The sections below are templates for each enrichment the undergrad will implement.\n",
    "Each shows what the metadata currently looks like, what it *should* look like\n",
    "per [OME-NGFF v0.5](https://ngff.openmicroscopy.org/latest/), and a prototype\n",
    "for writing it.\n",
    "\n",
    "### References\n",
    "- [OME-NGFF v0.5 spec](https://ngff.openmicroscopy.org/latest/)\n",
    "- [HCS plate layout](https://ngff.openmicroscopy.org/latest/#hcs-layout)\n",
    "- [BioHub spec](../../../zarr3_biohub_spec.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6a. Axis units\n",
    "\n",
    "**Current:** Axes have `name` and `type` but no `unit`.\n",
    "\n",
    "**Target:** Spatial axes should have `\"unit\": \"micrometer\"` per OME-NGFF spec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current axes\n",
    "print(\"Current axes (missing units):\")\n",
    "for ax in ms[\"axes\"]:\n",
    "    print(f\"  {ax}\")\n",
    "\n",
    "# What they should look like:\n",
    "target_axes = [\n",
    "    {\"name\": \"c\", \"type\": \"channel\"},\n",
    "    {\"name\": \"y\", \"type\": \"space\", \"unit\": \"micrometer\"},\n",
    "    {\"name\": \"x\", \"type\": \"space\", \"unit\": \"micrometer\"},\n",
    "]\n",
    "print(\"\\nTarget axes (with units):\")\n",
    "for ax in target_axes:\n",
    "    print(f\"  {ax}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6b. Pixel sizes in coordinateTransformations\n",
    "\n",
    "**Current:** All scale factors are `[1.0, 1.0, 1.0]` (placeholder).\n",
    "\n",
    "**Target:** Use real pixel sizes from the hardware metadata parquet.\n",
    "At level 0, scale = `[1.0, pixel_size_y, pixel_size_x]`.\n",
    "At level N, scale = `[1.0, pixel_size_y * 2^N, pixel_size_x * 2^N]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pixel sizes from hardware metadata\n",
    "px_x = ph_meta[\"pixel_size_x\"].iloc[0]\n",
    "px_y = ph_meta[\"pixel_size_y\"].iloc[0]\n",
    "print(f\"Pixel size from metadata: X={px_x} µm, Y={px_y} µm\")\n",
    "\n",
    "# Build correct coordinateTransformations for 5 pyramid levels\n",
    "coarsening_factor = 2\n",
    "n_levels = 5\n",
    "print(\"\\nTarget coordinateTransformations:\")\n",
    "for i in range(n_levels):\n",
    "    scale_y = px_y * (coarsening_factor**i)\n",
    "    scale_x = px_x * (coarsening_factor**i)\n",
    "    print(f\"  level {i}: scale=[1.0, {scale_y:.4f}, {scale_x:.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6c. Channel names\n",
    "\n",
    "**Current:** Channels are labeled `c0`, `c1`, `c2`, `c3` (generic).\n",
    "\n",
    "**Target:** Meaningful names from config, e.g., `DAPI`, `COXIV`, `CENPA`, `WGA`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current\n",
    "print(\"Current channel labels:\")\n",
    "for ch in omero.get(\"channels\", []):\n",
    "    print(f\"  {ch['label']}\")\n",
    "\n",
    "# From config\n",
    "phenotype_channels = [\"DAPI\", \"COXIV\", \"CENPA\", \"WGA\"]\n",
    "sbs_channels = [\"DAPI\", \"G\", \"T\", \"A\", \"C\"]\n",
    "\n",
    "print(f\"\\nTarget phenotype channels: {phenotype_channels}\")\n",
    "print(f\"Target SBS channels: {sbs_channels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6d. Contrast limits (rendering window)\n",
    "\n",
    "**Current:** No `window` key in channel metadata.\n",
    "\n",
    "**Target:** Each channel gets `\"window\": {\"start\": min, \"end\": max, \"min\": 0, \"max\": dtype_max}`\n",
    "computed from 1st/99th percentile intensity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute contrast limits from actual data\n",
    "img = read_image(tile_store)\n",
    "print(f\"Image shape: {img.shape} (channels, y, x)\")\n",
    "\n",
    "for i, ch_name in enumerate(phenotype_channels):\n",
    "    ch_data = img[i]\n",
    "    p1 = float(np.percentile(ch_data, 1))\n",
    "    p99 = float(np.percentile(ch_data, 99))\n",
    "    dtype_max = (\n",
    "        int(np.iinfo(ch_data.dtype).max)\n",
    "        if np.issubdtype(ch_data.dtype, np.integer)\n",
    "        else 1.0\n",
    "    )\n",
    "    print(\n",
    "        f\"  {ch_name}: window={{start: {p1:.0f}, end: {p99:.0f}, min: 0, max: {dtype_max}}}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6e. Label dtype and segmentation metadata\n",
    "\n",
    "**Current:** Labels may be float or have inconsistent dtypes.\n",
    "\n",
    "**Target:** Segmentation masks should be `int32`. The `image-label` attribute can\n",
    "include source info (method, label identity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check label dtypes across modules\n",
    "for label_path in sorted(ZARR_ROOT.rglob(\"nuclei.zarr\")):\n",
    "    root = zarr.open_group(str(label_path), mode=\"r\")\n",
    "    dtype = root[\"0\"].dtype\n",
    "    rel = label_path.relative_to(ZARR_ROOT)\n",
    "    status = \"OK\" if dtype == np.int32 else f\"NEEDS CONVERSION (currently {dtype})\"\n",
    "    print(f\"  {rel}: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Prototype: writing enriched metadata to a zarr store\n",
    "\n",
    "This shows how to modify a zarr store's `zarr.json` in place.\n",
    "The undergrad should use this pattern to implement each enrichment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import shutil\n",
    "\n",
    "# Work on a copy so we don't modify pipeline outputs\n",
    "demo_store = Path(\"./demo_enriched.zarr\")\n",
    "if demo_store.exists():\n",
    "    shutil.rmtree(demo_store)\n",
    "shutil.copytree(tile_store, demo_store)\n",
    "\n",
    "# Read current metadata\n",
    "with open(demo_store / \"zarr.json\") as f:\n",
    "    meta = json.load(f)\n",
    "\n",
    "# --- Enrich axes with units ---\n",
    "ms_meta = meta[\"attributes\"][\"ome\"][\"multiscales\"][0]\n",
    "for ax in ms_meta[\"axes\"]:\n",
    "    if ax[\"type\"] == \"space\":\n",
    "        ax[\"unit\"] = \"micrometer\"\n",
    "\n",
    "# --- Enrich pixel sizes ---\n",
    "px_x = ph_meta[\"pixel_size_x\"].iloc[0]\n",
    "px_y = ph_meta[\"pixel_size_y\"].iloc[0]\n",
    "for i, ds in enumerate(ms_meta[\"datasets\"]):\n",
    "    factor = 2**i\n",
    "    ds[\"coordinateTransformations\"] = [\n",
    "        {\"type\": \"scale\", \"scale\": [1.0, px_y * factor, px_x * factor]}\n",
    "    ]\n",
    "\n",
    "# --- Enrich channel names + contrast limits ---\n",
    "img = read_image(tile_store)\n",
    "channels_enriched = []\n",
    "for i, name in enumerate(phenotype_channels):\n",
    "    ch_data = img[i]\n",
    "    p1, p99 = float(np.percentile(ch_data, 1)), float(np.percentile(ch_data, 99))\n",
    "    dtype_max = (\n",
    "        int(np.iinfo(ch_data.dtype).max)\n",
    "        if np.issubdtype(ch_data.dtype, np.integer)\n",
    "        else 1.0\n",
    "    )\n",
    "    channels_enriched.append(\n",
    "        {\n",
    "            \"label\": name,\n",
    "            \"active\": True,\n",
    "            \"color\": \"FFFFFF\",\n",
    "            \"window\": {\"start\": p1, \"end\": p99, \"min\": 0, \"max\": dtype_max},\n",
    "        }\n",
    "    )\n",
    "meta[\"attributes\"][\"omero\"][\"channels\"] = channels_enriched\n",
    "\n",
    "# --- Write back ---\n",
    "with open(demo_store / \"zarr.json\", \"w\") as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "\n",
    "print(\"Enriched zarr.json:\")\n",
    "print(json.dumps(meta, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the enriched store still reads correctly\n",
    "img_enriched = read_image(demo_store)\n",
    "img_original = read_image(tile_store)\n",
    "print(\n",
    "    f\"Data unchanged after metadata enrichment: {np.array_equal(img_enriched, img_original)}\"\n",
    ")\n",
    "\n",
    "# Cleanup\n",
    "shutil.rmtree(demo_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## 8. What needs to happen in the pipeline\n\nOnce the enrichment logic is prototyped here, integrate it into the pipeline:\n\n1. **`save_image()` / `write_image_omezarr()`** — Accept and write richer metadata\n   (pixel sizes, channel names, contrast limits)\n2. **Snakemake rules** — Pass config values (pixel_size_um, channel names) as `params`\n3. **Scripts** — Forward `snakemake.params` metadata into `save_image()` calls\n4. **Config YAML** — Add `pixel_size_um`, channel name lists if not already present\n\n### Key question: does metadata propagate through read → process → write?\n\nTest this by:\n1. Write metadata to a store\n2. Read with `read_image()`\n3. Process the array (e.g., crop, filter)\n4. Write to a new store with `save_image()`\n5. Check: is the metadata preserved?\n\nCurrently `read_image()` returns a numpy array and discards metadata,\nso metadata will NOT propagate automatically. The pipeline needs explicit forwarding.\n\n### Visual validation with Napari\n\nAfter enriching metadata, verify it renders correctly in Napari using\n`tests/viewer/load_omezarr_in_napari.py`. That script reads the same\n`omero.pixel_size`, `omero.channels`, and `labels/` metadata you're writing here.\nIt uses `omero.channels[].window` for contrast limits when available, falling back\nto percentile-based limits otherwise — so enrichment has a visible effect.\n\n```bash\n# On your laptop (not cluster — needs a display)\nconda create -n napari-viz -c conda-forge python=3.11 napari zarr numpy -y\nconda activate napari-viz\n\n# Per-tile store:\npython tests/viewer/load_omezarr_in_napari.py output/sbs/images/1/A1/0/aligned.zarr\n\n# HCS field (labels nested under labels/):\npython tests/viewer/load_omezarr_in_napari.py output/sbs/hcs/1.zarr/A/1/0\n```\n\nWhat to check:\n- Channel names visible (not `c0`, `c1`, ...)\n- Scale bar shows correct physical coordinates\n- Contrast limits produce sensible default rendering\n- Segmentation labels overlay correctly on images"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate: metadata does NOT survive read → write roundtrip\n",
    "demo_src = Path(\"./demo_src.zarr\")\n",
    "demo_dst = Path(\"./demo_dst.zarr\")\n",
    "\n",
    "# Write with pixel sizes\n",
    "save_image(img_original, demo_src, pixel_size=0.65, channel_names=phenotype_channels)\n",
    "\n",
    "# Read back (only gets array, metadata is lost)\n",
    "arr = read_image(demo_src)\n",
    "\n",
    "# Write to new store (no metadata forwarded)\n",
    "save_image(arr, demo_dst)\n",
    "\n",
    "# Compare metadata\n",
    "with open(demo_src / \"zarr.json\") as f:\n",
    "    src_meta = json.load(f)\n",
    "with open(demo_dst / \"zarr.json\") as f:\n",
    "    dst_meta = json.load(f)\n",
    "\n",
    "src_channels = [ch[\"label\"] for ch in src_meta[\"attributes\"][\"omero\"][\"channels\"]]\n",
    "dst_channels = [ch[\"label\"] for ch in dst_meta[\"attributes\"][\"omero\"][\"channels\"]]\n",
    "print(f\"Source channels: {src_channels}\")\n",
    "print(f\"Dest channels:   {dst_channels}  ← reverted to generic names\")\n",
    "print(\"\\n→ Metadata must be explicitly forwarded through pipeline scripts.\")\n",
    "\n",
    "# Cleanup\n",
    "shutil.rmtree(demo_src)\n",
    "shutil.rmtree(demo_dst)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}