{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OME-Zarr Metadata Enrichment — Starter Notebook\n",
    "\n",
    "This notebook walks through the OME-Zarr outputs from the brieflow pipeline test data.\n",
    "It demonstrates how to inspect, enrich, and validate zarr store metadata so the undergrad\n",
    "can implement each enrichment step for real.\n",
    "\n",
    "**Prerequisites:** Run `bash run_brieflow_omezarr.sh` from the `small_test_analysis/` directory first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zarr\n",
    "\n",
    "# Add brieflow workflow to path so we can import its libraries\n",
    "sys.path.insert(0, str(Path(\"../../../workflow\").resolve()))\n",
    "from lib.shared.io import read_image, save_image\n",
    "\n",
    "# Root paths\n",
    "ZARR_ROOT = Path(\"../brieflow_output_zarr\")\n",
    "assert ZARR_ROOT.exists(), f\"Run the zarr pipeline first: {ZARR_ROOT}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Explore the output directory structure\n",
    "\n",
    "The pipeline writes zarr stores directly into HCS-compliant plate zarr directories.\n",
    "Each module has a `{plate}.zarr/` store with the nested hierarchy `{row}/{col}/{tile}/`,\n",
    "plus supporting tabular data in `parquets/`, `tsvs/`, and `eval/`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocess/  →  ['ic_fields', 'metadata', 'phenotype', 'sbs']\n",
      "sbs/  →  ['1.zarr', 'eval', 'parquets', 'tsvs']\n",
      "phenotype/  →  ['1.zarr', 'eval', 'parquets', 'tsvs']\n"
     ]
    }
   ],
   "source": [
    "for module in [\"preprocess\", \"sbs\", \"phenotype\"]:\n",
    "    module_dir = ZARR_ROOT / module\n",
    "    if not module_dir.exists():\n",
    "        continue\n",
    "    subdirs = sorted(d.name for d in module_dir.iterdir() if d.is_dir())\n",
    "    print(f\"{module}/  →  {subdirs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Read pipeline metadata (parquet)\n",
    "\n",
    "The preprocess module extracts hardware metadata from the raw images.\n",
    "This is where pixel sizes, channel info, and other acquisition parameters live."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (3, 15)\n",
      "Columns: ['x_pos', 'y_pos', 'z_pos', 'pfs_offset', 'plate', 'well', 'tile', 'filename', 'channels', 'pixel_size_x', 'pixel_size_y', 'pixel_size_z', 'objective_magnification', 'zoom_magnification', 'binning_xy']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_pos</th>\n",
       "      <th>y_pos</th>\n",
       "      <th>z_pos</th>\n",
       "      <th>pfs_offset</th>\n",
       "      <th>plate</th>\n",
       "      <th>well</th>\n",
       "      <th>tile</th>\n",
       "      <th>filename</th>\n",
       "      <th>channels</th>\n",
       "      <th>pixel_size_x</th>\n",
       "      <th>pixel_size_y</th>\n",
       "      <th>pixel_size_z</th>\n",
       "      <th>objective_magnification</th>\n",
       "      <th>zoom_magnification</th>\n",
       "      <th>binning_xy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41197.1</td>\n",
       "      <td>-36826.3</td>\n",
       "      <td>4034.02</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>A1</td>\n",
       "      <td>2</td>\n",
       "      <td>small_test_data/phenotype/empty_images/P001_Ph...</td>\n",
       "      <td>4</td>\n",
       "      <td>1.625</td>\n",
       "      <td>1.625</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38958.4</td>\n",
       "      <td>-36815.7</td>\n",
       "      <td>3165.58</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>A1</td>\n",
       "      <td>5</td>\n",
       "      <td>small_test_data/phenotype/real_images/P001_Phe...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.325</td>\n",
       "      <td>1.5</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41958.0</td>\n",
       "      <td>-32393.4</td>\n",
       "      <td>3153.32</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>A1</td>\n",
       "      <td>141</td>\n",
       "      <td>small_test_data/phenotype/real_images/P001_Phe...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.325</td>\n",
       "      <td>1.5</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     x_pos    y_pos    z_pos  pfs_offset  plate well  tile  \\\n",
       "0  41197.1 -36826.3  4034.02        <NA>      1   A1     2   \n",
       "1  38958.4 -36815.7  3165.58        <NA>      1   A1     5   \n",
       "2  41958.0 -32393.4  3153.32        <NA>      1   A1   141   \n",
       "\n",
       "                                            filename  channels  pixel_size_x  \\\n",
       "0  small_test_data/phenotype/empty_images/P001_Ph...         4         1.625   \n",
       "1  small_test_data/phenotype/real_images/P001_Phe...         4         0.325   \n",
       "2  small_test_data/phenotype/real_images/P001_Phe...         4         0.325   \n",
       "\n",
       "   pixel_size_y  pixel_size_z  objective_magnification  zoom_magnification  \\\n",
       "0         1.625           1.5                        4                   1   \n",
       "1         0.325           1.5                       20                   1   \n",
       "2         0.325           1.5                       20                   1   \n",
       "\n",
       "   binning_xy  \n",
       "0        <NA>  \n",
       "1        <NA>  \n",
       "2        <NA>  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read phenotype metadata\n",
    "ph_meta = pd.read_parquet(\n",
    "    ZARR_ROOT / \"preprocess/metadata/phenotype/1/A/1/combined_metadata.parquet\"\n",
    ")\n",
    "print(f\"Shape: {ph_meta.shape}\")\n",
    "print(f\"Columns: {list(ph_meta.columns)}\")\n",
    "ph_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixel sizes (from hardware):\n",
      "  X: 1.625 µm\n",
      "  Y: 1.625 µm\n",
      "  Z: 1.5 µm\n",
      "Objective: 4x\n",
      "Channels: 4\n"
     ]
    }
   ],
   "source": [
    "# Key fields for metadata enrichment\n",
    "print(\"Pixel sizes (from hardware):\")\n",
    "print(f\"  X: {ph_meta['pixel_size_x'].iloc[0]} µm\")\n",
    "print(f\"  Y: {ph_meta['pixel_size_y'].iloc[0]} µm\")\n",
    "print(f\"  Z: {ph_meta['pixel_size_z'].iloc[0]} µm\")\n",
    "print(f\"Objective: {ph_meta['objective_magnification'].iloc[0]}x\")\n",
    "print(f\"Channels: {ph_meta['channels'].iloc[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Inspect a per-tile zarr store\n",
    "\n",
    "Each tile is written directly into the HCS plate zarr at `{plate}.zarr/{row}/{col}/{tile}/`.\n",
    "Image stores within each tile (e.g., `aligned.zarr`, `illumination_corrected.zarr`) are\n",
    "independent OME-Zarr stores with pyramid levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== zarr.json ===\n",
      "{\n",
      "  \"attributes\": {\n",
      "    \"ome\": {\n",
      "      \"version\": \"0.5\",\n",
      "      \"multiscales\": [\n",
      "        {\n",
      "          \"datasets\": [\n",
      "            {\n",
      "              \"path\": \"0\",\n",
      "              \"coordinateTransformations\": [\n",
      "                {\n",
      "                  \"scale\": [\n",
      "                    1.0,\n",
      "                    1.0,\n",
      "                    1.0\n",
      "                  ],\n",
      "                  \"type\": \"scale\"\n",
      "                }\n",
      "              ]\n",
      "            },\n",
      "            {\n",
      "              \"path\": \"1\",\n",
      "              \"coordinateTransformations\": [\n",
      "                {\n",
      "                  \"scale\": [\n",
      "                    1.0,\n",
      "                    1.0,\n",
      "                    1.0\n",
      "                  ],\n",
      "                  \"type\": \"scale\"\n",
      "                }\n",
      "              ]\n",
      "            },\n",
      "            {\n",
      "              \"path\": \"2\",\n",
      "              \"coordinateTransformations\": [\n",
      "                {\n",
      "                  \"scale\": [\n",
      "                    1.0,\n",
      "                    1.0,\n",
      "                    1.0\n",
      "                  ],\n",
      "                  \"type\": \"scale\"\n",
      "                }\n",
      "              ]\n",
      "            },\n",
      "            {\n",
      "              \"path\": \"3\",\n",
      "              \"coordinateTransformations\": [\n",
      "                {\n",
      "                  \"scale\": [\n",
      "                    1.0,\n",
      "                    1.0,\n",
      "                    1.0\n",
      "                  ],\n",
      "                  \"type\": \"scale\"\n",
      "                }\n",
      "              ]\n",
      "            },\n",
      "            {\n",
      "              \"path\": \"4\",\n",
      "              \"coordinateTransformations\": [\n",
      "                {\n",
      "                  \"scale\": [\n",
      "                    1.0,\n",
      "                    1.0,\n",
      "                    1.0\n",
      "                  ],\n",
      "                  \"type\": \"scale\"\n",
      "                }\n",
      "              ]\n",
      "            }\n",
      "          ],\n",
      "          \"name\": \"/\",\n",
      "          \"axes\": [\n",
      "            {\n",
      "              \"name\": \"c\",\n",
      "              \"type\": \"channel\"\n",
      "            },\n",
      "            {\n",
      "              \"name\": \"y\",\n",
      "              \"type\": \"space\"\n",
      "            },\n",
      "            {\n",
      "              \"name\": \"x\",\n",
      "              \"type\": \"space\"\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    \"omero\": {\n",
      "      \"channels\": [\n",
      "        {\n",
      "          \"label\": \"c0\",\n",
      "          \"active\": true,\n",
      "          \"color\": \"FFFFFF\"\n",
      "        },\n",
      "        {\n",
      "          \"label\": \"c1\",\n",
      "          \"active\": true,\n",
      "          \"color\": \"FFFFFF\"\n",
      "        },\n",
      "        {\n",
      "          \"label\": \"c2\",\n",
      "          \"active\": true,\n",
      "          \"color\": \"FFFFFF\"\n",
      "        },\n",
      "        {\n",
      "          \"label\": \"c3\",\n",
      "          \"active\": true,\n",
      "          \"color\": \"FFFFFF\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  \"zarr_format\": 3,\n",
      "  \"consolidated_metadata\": null,\n",
      "  \"node_type\": \"group\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Pick a phenotype tile — direct-write path: {module}/{plate}.zarr/{row}/{col}/{tile}/\n",
    "tile_store = ZARR_ROOT / \"preprocess/phenotype/1.zarr/A/1/2/image.zarr\"\n",
    "\n",
    "# Read zarr.json (OME-NGFF v0.5 uses zarr v3 format)\n",
    "with open(tile_store / \"zarr.json\") as f:\n",
    "    tile_meta = json.load(f)\n",
    "\n",
    "print(\"=== zarr.json ===\")\n",
    "print(json.dumps(tile_meta, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Axes:\n",
      "  c (channel)  ←  MISSING: 'unit' key\n",
      "  y (space)  ←  MISSING: 'unit' key\n",
      "  x (space)  ←  MISSING: 'unit' key\n",
      "\n",
      "Pyramid levels:\n",
      "  level 0: scale=[1.0, 1.0, 1.0]  ←  MISSING: real pixel sizes\n",
      "  level 1: scale=[1.0, 1.0, 1.0]  ←  MISSING: real pixel sizes\n",
      "  level 2: scale=[1.0, 1.0, 1.0]  ←  MISSING: real pixel sizes\n",
      "  level 3: scale=[1.0, 1.0, 1.0]  ←  MISSING: real pixel sizes\n",
      "  level 4: scale=[1.0, 1.0, 1.0]  ←  MISSING: real pixel sizes\n",
      "\n",
      "Omero channels:\n",
      "  c0  ←  MISSING: real name, contrast window\n",
      "  c1  ←  MISSING: real name, contrast window\n",
      "  c2  ←  MISSING: real name, contrast window\n",
      "  c3  ←  MISSING: real name, contrast window\n"
     ]
    }
   ],
   "source": [
    "# Inspect the OME multiscale metadata\n",
    "ome = tile_meta[\"attributes\"][\"ome\"]\n",
    "ms = ome[\"multiscales\"][0]\n",
    "\n",
    "print(\"Axes:\")\n",
    "for ax in ms[\"axes\"]:\n",
    "    print(f\"  {ax['name']} ({ax['type']})  ←  MISSING: 'unit' key\")\n",
    "\n",
    "print(\"\\nPyramid levels:\")\n",
    "for ds in ms[\"datasets\"]:\n",
    "    scales = ds[\"coordinateTransformations\"][0][\"scale\"]\n",
    "    print(f\"  level {ds['path']}: scale={scales}  ←  MISSING: real pixel sizes\")\n",
    "\n",
    "print(\"\\nOmero channels:\")\n",
    "omero = tile_meta[\"attributes\"].get(\"omero\", {})\n",
    "for ch in omero.get(\"channels\", []):\n",
    "    print(f\"  {ch['label']}  ←  MISSING: real name, contrast window\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level 0: shape=(4, 2400, 2400), dtype=uint16, chunks=(4, 1024, 1024)\n",
      "Level 1: shape=(4, 1200, 1200), dtype=uint16, chunks=(4, 1024, 1024)\n",
      "Level 2: shape=(4, 600, 600), dtype=uint16, chunks=(4, 600, 600)\n",
      "Level 3: shape=(4, 300, 300), dtype=uint16, chunks=(4, 300, 300)\n",
      "Level 4: shape=(4, 150, 150), dtype=uint16, chunks=(4, 150, 150)\n"
     ]
    }
   ],
   "source": [
    "# Read image data at different pyramid levels\n",
    "root = zarr.open_group(str(tile_store), mode=\"r\")\n",
    "for level in [\"0\", \"1\", \"2\", \"3\", \"4\"]:\n",
    "    if level in root:\n",
    "        arr = root[level]\n",
    "        print(\n",
    "            f\"Level {level}: shape={arr.shape}, dtype={arr.dtype}, chunks={arr.chunks}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read_image() shape: (4, 2400, 2400), dtype: uint16\n",
      "  (singleton channel dim was squeezed: original zarr shape was (4, 2400, 2400))\n"
     ]
    }
   ],
   "source": [
    "# Compare: using the high-level read_image() API\n",
    "img = read_image(tile_store)\n",
    "print(f\"read_image() shape: {img.shape}, dtype: {img.dtype}\")\n",
    "print(\n",
    "    f\"  (singleton channel dim was squeezed: original zarr shape was {root['0'].shape})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Inspect a label store\n",
    "\n",
    "Segmentation outputs (nuclei, cells) live under a `labels/` group within each tile:\n",
    "`{plate}.zarr/{row}/{col}/{tile}/labels/nuclei.zarr`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is label store: True\n",
      "Label dtype: int64\n",
      "  <- Should be int32 for segmentation masks\n"
     ]
    }
   ],
   "source": [
    "# Labels now live inside the plate zarr: {plate}.zarr/{row}/{col}/{tile}/labels/\n",
    "label_store = ZARR_ROOT / \"sbs/1.zarr/A/1/0/labels/nuclei.zarr\"\n",
    "with open(label_store / \"zarr.json\") as f:\n",
    "    label_meta = json.load(f)\n",
    "\n",
    "is_label = \"image-label\" in label_meta.get(\"attributes\", {})\n",
    "print(f\"Is label store: {is_label}\")\n",
    "print(f\"Label dtype: {zarr.open_group(str(label_store), mode='r')['0'].dtype}\")\n",
    "print(f\"  <- Should be int32 for segmentation masks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Inspect the HCS plate structure\n",
    "\n",
    "With direct-write, there is **no separate `hcs/` directory**. The plate zarr IS the\n",
    "output directory. The finalize step writes metadata-only `zarr.json` files at plate,\n",
    "row, and well levels to make the hierarchy navigable.\n",
    "\n",
    "**Structure:**\n",
    "```\n",
    "{module}/{plate}.zarr/\n",
    "├── zarr.json                    <- plate metadata (rows, columns, wells)\n",
    "└── {row}/\n",
    "    ├── zarr.json                <- row group\n",
    "    └── {col}/\n",
    "        ├── zarr.json            <- well metadata (lists fields/tiles)\n",
    "        └── {tile}/\n",
    "            ├── aligned.zarr/    <- image stores (Snakemake writes these)\n",
    "            ├── ...\n",
    "            └── labels/\n",
    "                ├── zarr.json    <- labels group\n",
    "                ├── nuclei.zarr/\n",
    "                └── cells.zarr/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- sbs plate 1 ---\n",
      "  Rows: ['A']\n",
      "  Columns: ['1', '2']\n",
      "  Wells: ['A/1', 'A/2']\n",
      "  Fields in A/1: ['0', '2', '32']\n",
      "\n",
      "--- phenotype plate 1 ---\n",
      "  Rows: ['A']\n",
      "  Columns: ['1', '2']\n",
      "  Wells: ['A/1', 'A/2']\n",
      "  Fields in A/1: ['141', '2', '5']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect plate-level metadata for SBS and phenotype\n",
    "for module in [\"sbs\", \"phenotype\"]:\n",
    "    plate_path = ZARR_ROOT / f\"{module}/1.zarr\"\n",
    "    with open(plate_path / \"zarr.json\") as f:\n",
    "        pmeta = json.load(f)\n",
    "    plate = pmeta[\"attributes\"][\"ome\"][\"plate\"]\n",
    "    wells = [w[\"path\"] for w in plate[\"wells\"]]\n",
    "    print(f\"--- {module} plate 1 ---\")\n",
    "    print(f\"  Rows: {[r['name'] for r in plate['rows']]}\")\n",
    "    print(f\"  Columns: {[c['name'] for c in plate['columns']]}\")\n",
    "    print(f\"  Wells: {wells}\")\n",
    "\n",
    "    # Show fields in first well\n",
    "    well_dir = plate_path / wells[0]\n",
    "    with open(well_dir / \"zarr.json\") as f:\n",
    "        wmeta = json.load(f)\n",
    "    fields = [img[\"path\"] for img in wmeta[\"attributes\"][\"ome\"][\"well\"][\"images\"]]\n",
    "    print(f\"  Fields in {wells[0]}: {fields}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SBS plate metadata ===\n",
      "{\n",
      "  \"zarr_format\": 3,\n",
      "  \"node_type\": \"group\",\n",
      "  \"attributes\": {\n",
      "    \"ome\": {\n",
      "      \"version\": \"0.5\",\n",
      "      \"plate\": {\n",
      "        \"acquisitions\": [\n",
      "          {\n",
      "            \"id\": 0,\n",
      "            \"name\": \"default\"\n",
      "          }\n",
      "        ],\n",
      "        \"columns\": [\n",
      "          {\n",
      "            \"name\": \"1\"\n",
      "          },\n",
      "          {\n",
      "            \"name\": \"2\"\n",
      "          }\n",
      "        ],\n",
      "        \"rows\": [\n",
      "          {\n",
      "            \"name\": \"A\"\n",
      "          }\n",
      "        ],\n",
      "        \"wells\": [\n",
      "          {\n",
      "            \"path\": \"A/1\",\n",
      "            \"rowIndex\": 0,\n",
      "            \"columnIndex\": 0\n",
      "          },\n",
      "          {\n",
      "            \"path\": \"A/2\",\n",
      "            \"rowIndex\": 0,\n",
      "            \"columnIndex\": 1\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "=== Well A/1 metadata ===\n",
      "{\n",
      "  \"zarr_format\": 3,\n",
      "  \"node_type\": \"group\",\n",
      "  \"attributes\": {\n",
      "    \"ome\": {\n",
      "      \"version\": \"0.5\",\n",
      "      \"well\": {\n",
      "        \"images\": [\n",
      "          {\n",
      "            \"path\": \"0\",\n",
      "            \"acquisition\": 0\n",
      "          },\n",
      "          {\n",
      "            \"path\": \"2\",\n",
      "            \"acquisition\": 0\n",
      "          },\n",
      "          {\n",
      "            \"path\": \"32\",\n",
      "            \"acquisition\": 0\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Inspect plate + well + field metadata for SBS\n",
    "plate_path = ZARR_ROOT / \"sbs/1.zarr\"\n",
    "print(\"=== SBS plate metadata ===\")\n",
    "with open(plate_path / \"zarr.json\") as f:\n",
    "    print(json.dumps(json.load(f), indent=2))\n",
    "\n",
    "print(\"\\n=== Well A/1 metadata ===\")\n",
    "with open(plate_path / \"A/1/zarr.json\") as f:\n",
    "    print(json.dumps(json.load(f), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- sbs field ---\n",
      "  aligned.zarr                         (dir)\n",
      "  illumination_corrected.zarr          (dir)\n",
      "  labels                               (dir)\n",
      "  log_filtered.zarr                    (dir)\n",
      "  max_filtered.zarr                    (dir)\n",
      "  peaks.zarr                           (dir)\n",
      "  standard_deviation.zarr              (dir)\n",
      "\n",
      "--- phenotype field ---\n",
      "  aligned.zarr                         (dir)\n",
      "  illumination_corrected.zarr          (dir)\n",
      "  labels                               (dir)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Field contents: SBS vs phenotype (direct-write — no symlinks)\n",
    "for module, field_path in [\n",
    "    (\"sbs\", ZARR_ROOT / \"sbs/1.zarr/A/1/0\"),\n",
    "    (\"phenotype\", ZARR_ROOT / \"phenotype/1.zarr/A/1/2\"),\n",
    "]:\n",
    "    print(f\"--- {module} field ---\")\n",
    "    for item in sorted(field_path.iterdir()):\n",
    "        kind = \"dir\" if item.is_dir() else \"file\"\n",
    "        print(f\"  {item.name:35s}  ({kind})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- sbs labels ---\n",
      "  Available: ['cells', 'nuclei']\n",
      "  Nuclei shape: (1200, 1200), dtype: int64\n",
      "  Unique labels: 3686\n",
      "\n",
      "--- phenotype labels ---\n",
      "  Available: ['cells', 'identified_cytoplasms', 'nuclei']\n",
      "  Nuclei shape: (2400, 2400), dtype: uint16\n",
      "  Unique labels: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Labels: inspect the labels group within each tile\n",
    "for module, field_path in [\n",
    "    (\"sbs\", ZARR_ROOT / \"sbs/1.zarr/A/1/0\"),\n",
    "    (\"phenotype\", ZARR_ROOT / \"phenotype/1.zarr/A/1/2\"),\n",
    "]:\n",
    "    labels_path = field_path / \"labels\"\n",
    "    print(f\"--- {module} labels ---\")\n",
    "    with open(labels_path / \"zarr.json\") as f:\n",
    "        lmeta = json.load(f)\n",
    "    label_names = lmeta[\"attributes\"][\"ome\"][\"labels\"]\n",
    "    print(f\"  Available: {label_names}\")\n",
    "\n",
    "    # Read a label store\n",
    "    nuc = read_image(labels_path / \"nuclei.zarr\")\n",
    "    print(f\"  Nuclei shape: {nuc.shape}, dtype: {nuc.dtype}\")\n",
    "    print(f\"  Unique labels: {len(np.unique(nuc))}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocess plate zarrs:\n",
      "  preprocess/sbs/1.zarr: wells=['A/1', 'A/2']\n",
      "  preprocess/phenotype/1.zarr: wells=['A/1', 'A/2']\n",
      "\n",
      "Preprocess SBS field contents (per-cycle images):\n",
      "  1                               (dir)\n",
      "  10                              (dir)\n",
      "  11                              (dir)\n",
      "  2                               (dir)\n",
      "  3                               (dir)\n",
      "  4                               (dir)\n",
      "  5                               (dir)\n",
      "  6                               (dir)\n",
      "  7                               (dir)\n",
      "  8                               (dir)\n",
      "  9                               (dir)\n"
     ]
    }
   ],
   "source": [
    "# Preprocess has separate plate zarrs per modality (sbs/, phenotype/)\n",
    "print(\"Preprocess plate zarrs:\")\n",
    "for modality in [\"sbs\", \"phenotype\"]:\n",
    "    plate_path = ZARR_ROOT / f\"preprocess/{modality}/1.zarr\"\n",
    "    if not plate_path.exists():\n",
    "        continue\n",
    "    with open(plate_path / \"zarr.json\") as f:\n",
    "        pmeta = json.load(f)\n",
    "    wells = [w[\"path\"] for w in pmeta[\"attributes\"][\"ome\"][\"plate\"][\"wells\"]]\n",
    "    print(f\"  preprocess/{modality}/1.zarr: wells={wells}\")\n",
    "\n",
    "# Show preprocess SBS field — has per-cycle image subgroups\n",
    "field = ZARR_ROOT / \"preprocess/sbs/1.zarr/A/1/2\"\n",
    "print(f\"\\nPreprocess SBS field contents (per-cycle images):\")\n",
    "for item in sorted(field.iterdir()):\n",
    "    kind = \"dir\" if item.is_dir() else \"file\"\n",
    "    print(f\"  {item.name:30s}  ({kind})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Metadata enrichment tasks\n",
    "\n",
    "The sections below are templates for each enrichment the undergrad will implement.\n",
    "Each shows what the metadata currently looks like, what it *should* look like\n",
    "per [OME-NGFF v0.5](https://ngff.openmicroscopy.org/latest/), and a prototype\n",
    "for writing it.\n",
    "\n",
    "### References\n",
    "- [OME-NGFF v0.5 spec](https://ngff.openmicroscopy.org/latest/)\n",
    "- [HCS plate layout](https://ngff.openmicroscopy.org/latest/#hcs-layout)\n",
    "- [BioHub spec](../../../zarr3_biohub_spec.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6a. Axis units\n",
    "\n",
    "**Current:** Axes have `name` and `type` but no `unit`.\n",
    "\n",
    "**Target:** Spatial axes should have `\"unit\": \"micrometer\"` per OME-NGFF spec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current axes (missing units):\n",
      "  {'name': 'c', 'type': 'channel'}\n",
      "  {'name': 'y', 'type': 'space'}\n",
      "  {'name': 'x', 'type': 'space'}\n",
      "\n",
      "Target axes (with units):\n",
      "  {'name': 'c', 'type': 'channel'}\n",
      "  {'name': 'y', 'type': 'space', 'unit': 'micrometer'}\n",
      "  {'name': 'x', 'type': 'space', 'unit': 'micrometer'}\n"
     ]
    }
   ],
   "source": [
    "# Current axes\n",
    "print(\"Current axes (missing units):\")\n",
    "for ax in ms[\"axes\"]:\n",
    "    print(f\"  {ax}\")\n",
    "\n",
    "# What they should look like:\n",
    "target_axes = [\n",
    "    {\"name\": \"c\", \"type\": \"channel\"},\n",
    "    {\"name\": \"y\", \"type\": \"space\", \"unit\": \"micrometer\"},\n",
    "    {\"name\": \"x\", \"type\": \"space\", \"unit\": \"micrometer\"},\n",
    "]\n",
    "print(\"\\nTarget axes (with units):\")\n",
    "for ax in target_axes:\n",
    "    print(f\"  {ax}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6b. Pixel sizes in coordinateTransformations\n",
    "\n",
    "**Current:** All scale factors are `[1.0, 1.0, 1.0]` (placeholder).\n",
    "\n",
    "**Target:** Use real pixel sizes from the hardware metadata parquet.\n",
    "At level 0, scale = `[1.0, pixel_size_y, pixel_size_x]`.\n",
    "At level N, scale = `[1.0, pixel_size_y * 2^N, pixel_size_x * 2^N]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixel size from metadata: X=1.625 µm, Y=1.625 µm\n",
      "\n",
      "Target coordinateTransformations:\n",
      "  level 0: scale=[1.0, 1.6250, 1.6250]\n",
      "  level 1: scale=[1.0, 3.2500, 3.2500]\n",
      "  level 2: scale=[1.0, 6.5000, 6.5000]\n",
      "  level 3: scale=[1.0, 13.0000, 13.0000]\n",
      "  level 4: scale=[1.0, 26.0000, 26.0000]\n"
     ]
    }
   ],
   "source": [
    "# Get pixel sizes from hardware metadata\n",
    "px_x = ph_meta[\"pixel_size_x\"].iloc[0]\n",
    "px_y = ph_meta[\"pixel_size_y\"].iloc[0]\n",
    "print(f\"Pixel size from metadata: X={px_x} µm, Y={px_y} µm\")\n",
    "\n",
    "# Build correct coordinateTransformations for 5 pyramid levels\n",
    "coarsening_factor = 2\n",
    "n_levels = 5\n",
    "print(\"\\nTarget coordinateTransformations:\")\n",
    "for i in range(n_levels):\n",
    "    scale_y = px_y * (coarsening_factor**i)\n",
    "    scale_x = px_x * (coarsening_factor**i)\n",
    "    print(f\"  level {i}: scale=[1.0, {scale_y:.4f}, {scale_x:.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6c. Channel names\n",
    "\n",
    "**Current:** Channels are labeled `c0`, `c1`, `c2`, `c3` (generic).\n",
    "\n",
    "**Target:** Meaningful names from config, e.g., `DAPI`, `COXIV`, `CENPA`, `WGA`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current channel labels:\n",
      "  c0\n",
      "  c1\n",
      "  c2\n",
      "  c3\n",
      "\n",
      "Target phenotype channels: ['DAPI', 'COXIV', 'CENPA', 'WGA']\n",
      "Target SBS channels: ['DAPI', 'G', 'T', 'A', 'C']\n"
     ]
    }
   ],
   "source": [
    "# Current\n",
    "print(\"Current channel labels:\")\n",
    "for ch in omero.get(\"channels\", []):\n",
    "    print(f\"  {ch['label']}\")\n",
    "\n",
    "# From config\n",
    "phenotype_channels = [\"DAPI\", \"COXIV\", \"CENPA\", \"WGA\"]\n",
    "sbs_channels = [\"DAPI\", \"G\", \"T\", \"A\", \"C\"]\n",
    "\n",
    "print(f\"\\nTarget phenotype channels: {phenotype_channels}\")\n",
    "print(f\"Target SBS channels: {sbs_channels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6d. Contrast limits (rendering window)\n",
    "\n",
    "**Current:** No `window` key in channel metadata.\n",
    "\n",
    "**Target:** Each channel gets `\"window\": {\"start\": min, \"end\": max, \"min\": 0, \"max\": dtype_max}`\n",
    "computed from 1st/99th percentile intensity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (4, 2400, 2400) (channels, y, x)\n",
      "  DAPI: window={start: 103, end: 124, min: 0, max: 65535}\n",
      "  COXIV: window={start: 1584, end: 1952, min: 0, max: 65535}\n",
      "  CENPA: window={start: 116, end: 156, min: 0, max: 65535}\n",
      "  WGA: window={start: 1648, end: 2080, min: 0, max: 65535}\n"
     ]
    }
   ],
   "source": [
    "# Compute contrast limits from actual data\n",
    "img = read_image(tile_store)\n",
    "print(f\"Image shape: {img.shape} (channels, y, x)\")\n",
    "\n",
    "for i, ch_name in enumerate(phenotype_channels):\n",
    "    ch_data = img[i]\n",
    "    p1 = float(np.percentile(ch_data, 1))\n",
    "    p99 = float(np.percentile(ch_data, 99))\n",
    "    dtype_max = (\n",
    "        int(np.iinfo(ch_data.dtype).max)\n",
    "        if np.issubdtype(ch_data.dtype, np.integer)\n",
    "        else 1.0\n",
    "    )\n",
    "    print(\n",
    "        f\"  {ch_name}: window={{start: {p1:.0f}, end: {p99:.0f}, min: 0, max: {dtype_max}}}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6e. Label dtype and segmentation metadata\n",
    "\n",
    "**Current:** Labels may be float or have inconsistent dtypes.\n",
    "\n",
    "**Target:** Segmentation masks should be `int32`. The `image-label` attribute can\n",
    "include source info (method, label identity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  phenotype/1.zarr/A/1/141/labels/nuclei.zarr: NEEDS CONVERSION (currently int64)\n",
      "  phenotype/1.zarr/A/1/2/labels/nuclei.zarr: NEEDS CONVERSION (currently uint16)\n",
      "  phenotype/1.zarr/A/1/5/labels/nuclei.zarr: NEEDS CONVERSION (currently int64)\n",
      "  phenotype/1.zarr/A/2/141/labels/nuclei.zarr: NEEDS CONVERSION (currently int64)\n",
      "  phenotype/1.zarr/A/2/2/labels/nuclei.zarr: NEEDS CONVERSION (currently uint16)\n",
      "  phenotype/1.zarr/A/2/5/labels/nuclei.zarr: NEEDS CONVERSION (currently int64)\n",
      "  sbs/1.zarr/A/1/0/labels/nuclei.zarr: NEEDS CONVERSION (currently int64)\n",
      "  sbs/1.zarr/A/1/2/labels/nuclei.zarr: NEEDS CONVERSION (currently uint16)\n",
      "  sbs/1.zarr/A/1/32/labels/nuclei.zarr: NEEDS CONVERSION (currently int64)\n",
      "  sbs/1.zarr/A/2/0/labels/nuclei.zarr: NEEDS CONVERSION (currently int64)\n",
      "  sbs/1.zarr/A/2/2/labels/nuclei.zarr: NEEDS CONVERSION (currently uint16)\n",
      "  sbs/1.zarr/A/2/32/labels/nuclei.zarr: NEEDS CONVERSION (currently int64)\n"
     ]
    }
   ],
   "source": [
    "# Check label dtypes across modules\n",
    "for label_path in sorted(ZARR_ROOT.rglob(\"nuclei.zarr\")):\n",
    "    # Skip paths inside preprocess (those are raw images, not labels)\n",
    "    rel = label_path.relative_to(ZARR_ROOT)\n",
    "    if \"labels\" not in str(rel):\n",
    "        continue\n",
    "    root = zarr.open_group(str(label_path), mode=\"r\")\n",
    "    dtype = root[\"0\"].dtype\n",
    "    status = \"OK\" if dtype == np.int32 else f\"NEEDS CONVERSION (currently {dtype})\"\n",
    "    print(f\"  {rel}: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Prototype: writing enriched metadata to a zarr store\n",
    "\n",
    "This shows how to modify a zarr store's `zarr.json` in place.\n",
    "The undergrad should use this pattern to implement each enrichment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enriched zarr.json:\n",
      "{\n",
      "  \"attributes\": {\n",
      "    \"ome\": {\n",
      "      \"version\": \"0.5\",\n",
      "      \"multiscales\": [\n",
      "        {\n",
      "          \"datasets\": [\n",
      "            {\n",
      "              \"path\": \"0\",\n",
      "              \"coordinateTransformations\": [\n",
      "                {\n",
      "                  \"type\": \"scale\",\n",
      "                  \"scale\": [\n",
      "                    1.0,\n",
      "                    1.625,\n",
      "                    1.625\n",
      "                  ]\n",
      "                }\n",
      "              ]\n",
      "            },\n",
      "            {\n",
      "              \"path\": \"1\",\n",
      "              \"coordinateTransformations\": [\n",
      "                {\n",
      "                  \"type\": \"scale\",\n",
      "                  \"scale\": [\n",
      "                    1.0,\n",
      "                    3.25,\n",
      "                    3.25\n",
      "                  ]\n",
      "                }\n",
      "              ]\n",
      "            },\n",
      "            {\n",
      "              \"path\": \"2\",\n",
      "              \"coordinateTransformations\": [\n",
      "                {\n",
      "                  \"type\": \"scale\",\n",
      "                  \"scale\": [\n",
      "                    1.0,\n",
      "                    6.5,\n",
      "                    6.5\n",
      "                  ]\n",
      "                }\n",
      "              ]\n",
      "            },\n",
      "            {\n",
      "              \"path\": \"3\",\n",
      "              \"coordinateTransformations\": [\n",
      "                {\n",
      "                  \"type\": \"scale\",\n",
      "                  \"scale\": [\n",
      "                    1.0,\n",
      "                    13.0,\n",
      "                    13.0\n",
      "                  ]\n",
      "                }\n",
      "              ]\n",
      "            },\n",
      "            {\n",
      "              \"path\": \"4\",\n",
      "              \"coordinateTransformations\": [\n",
      "                {\n",
      "                  \"type\": \"scale\",\n",
      "                  \"scale\": [\n",
      "                    1.0,\n",
      "                    26.0,\n",
      "                    26.0\n",
      "                  ]\n",
      "                }\n",
      "              ]\n",
      "            }\n",
      "          ],\n",
      "          \"name\": \"/\",\n",
      "          \"axes\": [\n",
      "            {\n",
      "              \"name\": \"c\",\n",
      "              \"type\": \"channel\"\n",
      "            },\n",
      "            {\n",
      "              \"name\": \"y\",\n",
      "              \"type\": \"space\",\n",
      "              \"unit\": \"micrometer\"\n",
      "            },\n",
      "            {\n",
      "              \"name\": \"x\",\n",
      "              \"type\": \"space\",\n",
      "              \"unit\": \"micrometer\"\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    \"omero\": {\n",
      "      \"channels\": [\n",
      "        {\n",
      "          \"label\": \"DAPI\",\n",
      "          \"active\": true,\n",
      "          \"color\": \"FFFFFF\",\n",
      "          \"window\": {\n",
      "            \"start\": 103.0,\n",
      "            \"end\": 124.0,\n",
      "            \"min\": 0,\n",
      "            \"max\": 65535\n",
      "          }\n",
      "        },\n",
      "        {\n",
      "          \"label\": \"COXIV\",\n",
      "          \"active\": true,\n",
      "          \"color\": \"FFFFFF\",\n",
      "          \"window\": {\n",
      "            \"start\": 1584.0,\n",
      "            \"end\": 1952.0,\n",
      "            \"min\": 0,\n",
      "            \"max\": 65535\n",
      "          }\n",
      "        },\n",
      "        {\n",
      "          \"label\": \"CENPA\",\n",
      "          \"active\": true,\n",
      "          \"color\": \"FFFFFF\",\n",
      "          \"window\": {\n",
      "            \"start\": 116.0,\n",
      "            \"end\": 156.0,\n",
      "            \"min\": 0,\n",
      "            \"max\": 65535\n",
      "          }\n",
      "        },\n",
      "        {\n",
      "          \"label\": \"WGA\",\n",
      "          \"active\": true,\n",
      "          \"color\": \"FFFFFF\",\n",
      "          \"window\": {\n",
      "            \"start\": 1648.0,\n",
      "            \"end\": 2080.0,\n",
      "            \"min\": 0,\n",
      "            \"max\": 65535\n",
      "          }\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  \"zarr_format\": 3,\n",
      "  \"consolidated_metadata\": null,\n",
      "  \"node_type\": \"group\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import shutil\n",
    "\n",
    "# Work on a copy so we don't modify pipeline outputs\n",
    "demo_store = Path(\"./demo_enriched.zarr\")\n",
    "if demo_store.exists():\n",
    "    shutil.rmtree(demo_store)\n",
    "shutil.copytree(tile_store, demo_store)\n",
    "\n",
    "# Read current metadata\n",
    "with open(demo_store / \"zarr.json\") as f:\n",
    "    meta = json.load(f)\n",
    "\n",
    "# --- Enrich axes with units ---\n",
    "ms_meta = meta[\"attributes\"][\"ome\"][\"multiscales\"][0]\n",
    "for ax in ms_meta[\"axes\"]:\n",
    "    if ax[\"type\"] == \"space\":\n",
    "        ax[\"unit\"] = \"micrometer\"\n",
    "\n",
    "# --- Enrich pixel sizes ---\n",
    "px_x = ph_meta[\"pixel_size_x\"].iloc[0]\n",
    "px_y = ph_meta[\"pixel_size_y\"].iloc[0]\n",
    "for i, ds in enumerate(ms_meta[\"datasets\"]):\n",
    "    factor = 2**i\n",
    "    ds[\"coordinateTransformations\"] = [\n",
    "        {\"type\": \"scale\", \"scale\": [1.0, px_y * factor, px_x * factor]}\n",
    "    ]\n",
    "\n",
    "# --- Enrich channel names + contrast limits ---\n",
    "img = read_image(tile_store)\n",
    "channels_enriched = []\n",
    "for i, name in enumerate(phenotype_channels):\n",
    "    ch_data = img[i]\n",
    "    p1, p99 = float(np.percentile(ch_data, 1)), float(np.percentile(ch_data, 99))\n",
    "    dtype_max = (\n",
    "        int(np.iinfo(ch_data.dtype).max)\n",
    "        if np.issubdtype(ch_data.dtype, np.integer)\n",
    "        else 1.0\n",
    "    )\n",
    "    channels_enriched.append(\n",
    "        {\n",
    "            \"label\": name,\n",
    "            \"active\": True,\n",
    "            \"color\": \"FFFFFF\",\n",
    "            \"window\": {\"start\": p1, \"end\": p99, \"min\": 0, \"max\": dtype_max},\n",
    "        }\n",
    "    )\n",
    "meta[\"attributes\"][\"omero\"][\"channels\"] = channels_enriched\n",
    "\n",
    "# --- Write back ---\n",
    "with open(demo_store / \"zarr.json\", \"w\") as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "\n",
    "print(\"Enriched zarr.json:\")\n",
    "print(json.dumps(meta, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data unchanged after metadata enrichment: True\n"
     ]
    }
   ],
   "source": [
    "# Verify the enriched store still reads correctly\n",
    "img_enriched = read_image(demo_store)\n",
    "img_original = read_image(tile_store)\n",
    "print(\n",
    "    f\"Data unchanged after metadata enrichment: {np.array_equal(img_enriched, img_original)}\"\n",
    ")\n",
    "\n",
    "# Cleanup\n",
    "shutil.rmtree(demo_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. What needs to happen in the pipeline\n",
    "\n",
    "Once the enrichment logic is prototyped here, integrate it into the pipeline:\n",
    "\n",
    "1. **`save_image()` / `write_image_omezarr()`** — Accept and write richer metadata\n",
    "   (pixel sizes, channel names, contrast limits)\n",
    "2. **Snakemake rules** — Pass config values (pixel_size_um, channel names) as `params`\n",
    "3. **Scripts** — Forward `snakemake.params` metadata into `save_image()` calls\n",
    "4. **Config YAML** — Add `pixel_size_um`, channel name lists if not already present\n",
    "\n",
    "### iohub for metadata automation\n",
    "\n",
    "[iohub](https://github.com/czbiohub-sf/iohub) (CZ Biohub) can read/write OME-Zarr\n",
    "with rich metadata handling. It may be useful for:\n",
    "- Automatically deriving metadata from pipeline data (channel names from config,\n",
    "  pixel sizes from hardware metadata parquets)\n",
    "- Writing compliant HCS metadata more efficiently than manual zarr.json editing\n",
    "- Validating our output against the OME-NGFF spec\n",
    "\n",
    "Evaluate whether iohub can replace or complement the manual metadata writing approach.\n",
    "\n",
    "### Key question: does metadata propagate through read -> process -> write?\n",
    "\n",
    "Test this by:\n",
    "1. Write metadata to a store\n",
    "2. Read with `read_image()`\n",
    "3. Process the array (e.g., crop, filter)\n",
    "4. Write to a new store with `save_image()`\n",
    "5. Check: is the metadata preserved?\n",
    "\n",
    "Currently `read_image()` returns a numpy array and discards metadata,\n",
    "so metadata will NOT propagate automatically. The pipeline needs explicit forwarding.\n",
    "\n",
    "### Visual validation with Napari\n",
    "\n",
    "After enriching metadata, verify it renders correctly in Napari using\n",
    "`tests/viewer/load_omezarr_in_napari.py`.\n",
    "\n",
    "```bash\n",
    "# On your laptop (not cluster -- needs a display)\n",
    "conda create -n napari-viz -c conda-forge python=3.11 napari zarr numpy -y\n",
    "conda activate napari-viz\n",
    "\n",
    "# Per-tile store (direct-write path):\n",
    "python tests/viewer/load_omezarr_in_napari.py output/sbs/1.zarr/A/1/0/aligned.zarr\n",
    "\n",
    "# HCS field (labels nested under labels/):\n",
    "python tests/viewer/load_omezarr_in_napari.py output/sbs/1.zarr/A/1/0\n",
    "```\n",
    "\n",
    "What to check:\n",
    "- Channel names visible (not `c0`, `c1`, ...)\n",
    "- Scale bar shows correct physical coordinates\n",
    "- Contrast limits produce sensible default rendering\n",
    "- Segmentation labels overlay correctly on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source channels: ['DAPI', 'COXIV', 'CENPA', 'WGA']\n",
      "Dest channels:   ['c0', 'c1', 'c2', 'c3']  ← reverted to generic names\n",
      "\n",
      "→ Metadata must be explicitly forwarded through pipeline scripts.\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate: metadata does NOT survive read → write roundtrip\n",
    "demo_src = Path(\"./demo_src.zarr\")\n",
    "demo_dst = Path(\"./demo_dst.zarr\")\n",
    "\n",
    "# Write with pixel sizes\n",
    "save_image(img_original, demo_src, pixel_size=0.65, channel_names=phenotype_channels)\n",
    "\n",
    "# Read back (only gets array, metadata is lost)\n",
    "arr = read_image(demo_src)\n",
    "\n",
    "# Write to new store (no metadata forwarded)\n",
    "save_image(arr, demo_dst)\n",
    "\n",
    "# Compare metadata\n",
    "with open(demo_src / \"zarr.json\") as f:\n",
    "    src_meta = json.load(f)\n",
    "with open(demo_dst / \"zarr.json\") as f:\n",
    "    dst_meta = json.load(f)\n",
    "\n",
    "src_channels = [ch[\"label\"] for ch in src_meta[\"attributes\"][\"omero\"][\"channels\"]]\n",
    "dst_channels = [ch[\"label\"] for ch in dst_meta[\"attributes\"][\"omero\"][\"channels\"]]\n",
    "print(f\"Source channels: {src_channels}\")\n",
    "print(f\"Dest channels:   {dst_channels}  ← reverted to generic names\")\n",
    "print(\"\\n→ Metadata must be explicitly forwarded through pipeline scripts.\")\n",
    "\n",
    "# Cleanup\n",
    "shutil.rmtree(demo_src)\n",
    "shutil.rmtree(demo_dst)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brieflow_SCREEN_NAME",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
