import warnings
from pathlib import Path
import pandas as pd

from lib.preprocess.file_utils import get_metadata_wildcard_combos
from lib.shared.initialize_paramsearch import initialize_segment_sbs_paramsearch
from lib.shared.initialize_paramsearch import initialize_segment_phenotype_paramsearch

def file_exists(path):
    """Check if file exists (handles both local and GCS paths)"""
    if isinstance(path, str) and path.startswith("gs://"):
        # For GCS paths, we can't easily check existence without downloading
        # So we assume they exist and let pandas handle the error
        return True
    elif path is None:
        return False
    else:
        return Path(path).exists()

# Get the general configuration options
ROOT_FP = Path(config["all"]["root_fp"])

# Get paths to the sample and combo files dfs
# Keep as strings for GCS compatibility - don't use Path() for gs:// URLs
SBS_SAMPLES_FP = config["preprocess"]["sbs_samples_fp"]
SBS_COMBO_FP = config["preprocess"]["sbs_combo_fp"]
PHENOTYPE_SAMPLES_FP = config["preprocess"]["phenotype_samples_fp"]
PHENOTYPE_COMBO_FP = config["preprocess"]["phenotype_combo_fp"]
SBS_METADATA_SAMPLES_DF_FP = config["preprocess"].get("sbs_metadata_samples_df_fp")
PHENOTYPE_METADATA_SAMPLES_DF_FP = config["preprocess"].get("phenotype_metadata_samples_df_fp")

# Load sbs samples if the file exists
if file_exists(SBS_SAMPLES_FP):
    sbs_samples_df = pd.read_csv(SBS_SAMPLES_FP, sep="\t", storage_options={"project": "lasagna-199723"})
    if len(sbs_samples_df) > 0:
        sbs_wildcard_combos = pd.read_csv(SBS_COMBO_FP, sep="\t", storage_options={"project": "lasagna-199723"}).astype(str)
        if file_exists(SBS_METADATA_SAMPLES_DF_FP):
            sbs_metadata_samples_df = pd.read_csv(SBS_METADATA_SAMPLES_DF_FP, sep="\t", storage_options={"project": "lasagna-199723"})
        else:
            sbs_metadata_samples_df = pd.DataFrame()
    else:
        print("No SBS samples found in the file!")
        sbs_wildcard_combos = pd.DataFrame(columns=["plate", "well", "tile", "cycle"]).astype(str)
        sbs_metadata_samples_df = pd.DataFrame()
else:
    print(f"SBS samples file not found: {SBS_SAMPLES_FP}")
    sbs_samples_df = pd.DataFrame()
    sbs_wildcard_combos = pd.DataFrame(columns=["plate", "well", "tile", "cycle"]).astype(str)
    sbs_metadata_samples_df = pd.DataFrame()

# Load phenotype samples if the file exists
if file_exists(PHENOTYPE_SAMPLES_FP):
    phenotype_samples_df = pd.read_csv(PHENOTYPE_SAMPLES_FP, sep="\t", storage_options={"project": "lasagna-199723"})
    if len(phenotype_samples_df) > 0:
        phenotype_wildcard_combos = pd.read_csv(PHENOTYPE_COMBO_FP, sep="\t", storage_options={"project": "lasagna-199723"}).astype(str)
        if file_exists(PHENOTYPE_METADATA_SAMPLES_DF_FP):
            phenotype_metadata_samples_df = pd.read_csv(PHENOTYPE_METADATA_SAMPLES_DF_FP, sep="\t", storage_options={"project": "lasagna-199723"})
        else:
            phenotype_metadata_samples_df = pd.DataFrame()
    else:
        print("No phenotype samples found in the file!")
        phenotype_wildcard_combos = pd.DataFrame(columns=["plate", "well", "tile"]).astype(str)
        phenotype_metadata_samples_df = pd.DataFrame()
else:
    print(f"Phenotype samples file not found: {PHENOTYPE_SAMPLES_FP}")
    phenotype_samples_df = pd.DataFrame()
    phenotype_wildcard_combos = pd.DataFrame(columns=["plate", "well", "tile"]).astype(str)
    phenotype_metadata_samples_df = pd.DataFrame()

# Generate metadata-specific wildcard combinations
sbs_metadata_wildcard_combos = get_metadata_wildcard_combos(sbs_samples_df, sbs_metadata_samples_df)
phenotype_metadata_wildcard_combos = get_metadata_wildcard_combos(phenotype_samples_df, phenotype_metadata_samples_df)

print(f"SBS metadata jobs: {len(sbs_metadata_wildcard_combos)} (columns: {list(sbs_metadata_wildcard_combos.columns) if len(sbs_metadata_wildcard_combos) > 0 else 'none'})")
print(f"SBS image processing jobs: {len(sbs_wildcard_combos)} (columns: {list(sbs_wildcard_combos.columns) if len(sbs_wildcard_combos) > 0 else 'none'})")

# Check for plate filter
# If plate filter is set, only process the specified plate
plate_filter = config.get("plate_filter", None)
if plate_filter is not None:
    plate_filter = str(plate_filter)
    print(f"PLATE FILTER: Processing only plate {plate_filter}")

    if len(sbs_samples_df) > 0:
        sbs_samples_df = sbs_samples_df[sbs_samples_df["plate"].astype(str) == plate_filter]
        sbs_wildcard_combos = sbs_wildcard_combos[sbs_wildcard_combos["plate"] == plate_filter]
        sbs_metadata_wildcard_combos = sbs_metadata_wildcard_combos[sbs_metadata_wildcard_combos["plate"] == plate_filter]
        if len(sbs_metadata_samples_df) > 0:
            sbs_metadata_samples_df = sbs_metadata_samples_df[sbs_metadata_samples_df["plate"].astype(str) == plate_filter]
        print(f"Filtered SBS samples to {len(sbs_samples_df)} rows for plate {plate_filter}")
        
    if len(phenotype_samples_df) > 0:
        phenotype_samples_df = phenotype_samples_df[phenotype_samples_df["plate"].astype(str) == plate_filter]
        phenotype_wildcard_combos = phenotype_wildcard_combos[phenotype_wildcard_combos["plate"] == plate_filter]
        phenotype_metadata_wildcard_combos = phenotype_metadata_wildcard_combos[phenotype_metadata_wildcard_combos["plate"] == plate_filter]
        if len(phenotype_metadata_samples_df) > 0:
            phenotype_metadata_samples_df = phenotype_metadata_samples_df[phenotype_metadata_samples_df["plate"].astype(str) == plate_filter]
        print(f"Filtered phenotype samples to {len(phenotype_samples_df)} rows for plate {plate_filter}")

include: "targets/preprocess.smk"
include: "rules/preprocess.smk"


if "sbs" in config and len(sbs_wildcard_combos) > 0:
    # TODO: test and implement segmentation paramsearch for updated brieflow setup
    # # Initialize parameter search configurations if needed
    # if config["sbs"]["mode"] == "segment_sbs_paramsearch":
    #     config = initialize_segment_sbs_paramsearch(config)

    # Include target and rule files
    include: "targets/sbs.smk"
    include: "rules/sbs.smk"


if "phenotype" in config and len(phenotype_wildcard_combos) > 0:
    # TODO: test and implement segmentation paramsearch for updated brieflow setup
    # # Initialize parameter search configurations if needed
    # if config["phenotype"]["mode"] == "segment_phenotype_paramsearch":
    #     config = initialize_segment_phenotype_paramsearch(config)

    # Include target and rule files
    include: "targets/phenotype.smk"
    include: "rules/phenotype.smk"


if "merge" in config:
    MERGE_COMBO_FP = config["merge"]["merge_combo_fp"]
    merge_wildcard_combos = pd.read_csv(MERGE_COMBO_FP, sep="\t", storage_options={"project": "lasagna-199723"})

    # Include target and rule files
    include: "targets/merge.smk"
    include: "rules/merge.smk"


if "aggregate" in config:
    AGGREGATE_COMBO_FP = config["aggregate"]["aggregate_combo_fp"]
    aggregate_wildcard_combos = pd.read_csv(AGGREGATE_COMBO_FP, sep="\t", storage_options={"project": "lasagna-199723"})

    # Include target and rule files
    include: "targets/aggregate.smk"
    include: "rules/aggregate.smk"


if "cluster" in config:
    CLUSTER_COMBO_FP = config["cluster"]["cluster_combo_fp"]
    cluster_wildcard_combos = pd.read_csv(CLUSTER_COMBO_FP, sep="\t", storage_options={"project": "lasagna-199723"})

    # Include target and rule files
    include: "targets/cluster.smk"
    include: "rules/cluster.smk"
